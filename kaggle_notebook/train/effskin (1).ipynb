{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7371477,"sourceType":"datasetVersion","datasetId":4283024},{"sourceId":7407946,"sourceType":"datasetVersion","datasetId":4308453}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport os\nimport cv2\nimport numpy as np\nfrom torchvision.transforms import Compose, Resize, ToTensor, Normalize, ToPILImage, v2, CenterCrop\n\nclass SkinDataset(Dataset):\n    def __init__(self, root='/kaggle/input/huhuhu7/skintone/', train=True, transform=None):\n        super().__init__()\n        self.image_paths = []\n        self.labels = []\n        self.categories = [\"dark\", \"light\", \"mid-dark\", \"mid-light\"]\n        self.transform = transform\n        \n        if train:\n            data_path = os.path.join(root, 'train')\n        else:\n            data_path = os.path.join(root, 'valid')\n        \n        for i, category in enumerate(self.categories):\n            data_files = os.path.join(data_path,category)\n            for item in os.listdir(data_files):\n                path = os.path.join(data_files,item)\n                self.image_paths.append(path)\n                self.labels.append(i)\n        \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        image = cv2.imread(image_path)\n        label = self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-15T17:49:13.317304Z","iopub.execute_input":"2024-01-15T17:49:13.318029Z","iopub.status.idle":"2024-01-15T17:49:16.944041Z","shell.execute_reply.started":"2024-01-15T17:49:13.318001Z","shell.execute_reply":"2024-01-15T17:49:16.943110Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n  warnings.warn(_BETA_TRANSFORMS_WARNING)\n/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n  warnings.warn(_BETA_TRANSFORMS_WARNING)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_transform = Compose([\n        ToPILImage(),\n        Resize(256),\n        CenterCrop(224),\n#         ToTensor(),\n        v2.RandomHorizontalFlip(p=0.5),\n        ToTensor(),\n        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\ntest_transform = Compose([\n        ToPILImage(),\n        Resize(256),\n        CenterCrop(224),\n        ToTensor(),\n        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ]) \nroot = '/kaggle/input/huhuhu7/skintone/'\ntrain_dataset = SkinDataset(root=root, train=True, transform=train_transform)\nprint(train_dataset.__len__())\ntest_dataset = SkinDataset(root=root, train=False, transform=test_transform)\nprint(test_dataset.__len__())\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=8, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False)\n\n# for images, labels in train_loader:\n#     print(images.shape, labels.shape)\n# for images, labels in test_loader:\n#     print(images.shape, labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:49:16.945767Z","iopub.execute_input":"2024-01-15T17:49:16.946144Z","iopub.status.idle":"2024-01-15T17:49:18.577830Z","shell.execute_reply.started":"2024-01-15T17:49:16.946120Z","shell.execute_reply":"2024-01-15T17:49:18.576910Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"19204\n3058\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport os\nimport cv2\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom tqdm import tqdm\nfrom torchvision.transforms import Compose, Resize, ToTensor, Normalize, ToPILImage, RandomResizedCrop","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:49:18.578889Z","iopub.execute_input":"2024-01-15T17:49:18.579191Z","iopub.status.idle":"2024-01-15T17:49:19.450831Z","shell.execute_reply.started":"2024-01-15T17:49:18.579167Z","shell.execute_reply":"2024-01-15T17:49:19.449829Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchvision.models import resnet50, ResNet50_Weights, efficientnet_v2_m, EfficientNet_V2_M_Weights\nimport torch\nimport torch.nn as nn\n\nclass MyEffnet(nn.Module):\n    def __init__(self, n_classes=4):\n        super().__init__()\n        self.backbone = efficientnet_v2_m(weights=EfficientNet_V2_M_Weights.DEFAULT)\n        self.backbone.classifier[1] = nn.Linear(1280, n_classes)\n    \n    def forward(self, x):\n        x = self.backbone(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:50:28.068580Z","iopub.execute_input":"2024-01-15T17:50:28.069462Z","iopub.status.idle":"2024-01-15T17:50:28.075405Z","shell.execute_reply.started":"2024-01-15T17:50:28.069429Z","shell.execute_reply":"2024-01-15T17:50:28.074482Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"x = torch.randn(16, 3, 224, 224)\nmodel = MyEffnet()\n# print(model)\nprint(model(x).shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:50:28.604322Z","iopub.execute_input":"2024-01-15T17:50:28.604598Z","iopub.status.idle":"2024-01-15T17:50:33.833847Z","shell.execute_reply.started":"2024-01-15T17:50:28.604576Z","shell.execute_reply":"2024-01-15T17:50:33.832892Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_v2_m-dc08266a.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_m-dc08266a.pth\n100%|██████████| 208M/208M [00:00<00:00, 336MB/s] \n","output_type":"stream"},{"name":"stdout","text":"torch.Size([16, 4])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.optim as optim\nfrom tqdm import tqdm\nepochs = 40\nbatch_size = 8\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3, amsgrad=True)#optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\nnum_workers = 2\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ntrain_transform = Compose([\n        ToPILImage(),\n        Resize(256),\n        CenterCrop(224),\n#         ToTensor(),\n        v2.RandomHorizontalFlip(p=0.5),\n        ToTensor(),\n        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\ntest_transform = Compose([\n        ToPILImage(),\n        Resize(256),\n        CenterCrop(224),\n        ToTensor(),\n        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ]) ","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:50:33.835870Z","iopub.execute_input":"2024-01-15T17:50:33.836139Z","iopub.status.idle":"2024-01-15T17:50:33.876203Z","shell.execute_reply.started":"2024-01-15T17:50:33.836116Z","shell.execute_reply":"2024-01-15T17:50:33.875160Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset = SkinDataset(root= root, train=True, transform=train_transform)\nprint(train_dataset.__len__())\ntest_dataset = SkinDataset(root=root, train=False, transform=test_transform)\nprint(test_dataset.__len__())\ntrain_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\ntest_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:50:33.877285Z","iopub.execute_input":"2024-01-15T17:50:33.877642Z","iopub.status.idle":"2024-01-15T17:50:33.949955Z","shell.execute_reply.started":"2024-01-15T17:50:33.877616Z","shell.execute_reply":"2024-01-15T17:50:33.949114Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"19204\n3058\n","output_type":"stream"}]},{"cell_type":"code","source":"model = MyEffnet().to(device)\nif os.path.exists('last.pt'):\n    if torch.cuda.is_available():\n        model.load_state_dict(torch.load('last.pt'))\n    else:\n        model.load_state_dict(torch.load('last.pt', map_location=torch.device('cpu')))\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3) ","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:50:33.952017Z","iopub.execute_input":"2024-01-15T17:50:33.952350Z","iopub.status.idle":"2024-01-15T17:50:35.241446Z","shell.execute_reply.started":"2024-01-15T17:50:33.952319Z","shell.execute_reply":"2024-01-15T17:50:35.240338Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"best_acc = 0\nbest_model = MyEffnet().to(device)\nif os.path.exists('best.pt'):\n    best_model.load_state_dict(torch.load('best.pt',map_location=torch.device('cpu')))\n    best_model.eval()\n    all_predictions_best = []\n    all_labels_best = []\n    for iter, (images, labels) in enumerate(test_dataloader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        with torch.no_grad():\n            outputs = best_model(images)\n            loss = criterion(outputs, labels)\n            predictions = torch.argmax(outputs.cpu(), dim=1)\n            all_predictions_best.extend(predictions)\n            all_labels_best.extend(labels.cpu())     \n    all_labels_best = [label.item() for label in all_labels_best]\n    all_predictions_best = [prediction.item() for prediction in all_predictions_best]\n    best_acc = accuracy_score(all_labels_best, all_predictions_best)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:50:35.242444Z","iopub.execute_input":"2024-01-15T17:50:35.242730Z","iopub.status.idle":"2024-01-15T17:50:36.336158Z","shell.execute_reply.started":"2024-01-15T17:50:35.242706Z","shell.execute_reply":"2024-01-15T17:50:36.335380Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"epochs=20\nfor epoch in range(epochs):\n    model.train()\n    progress_bar = tqdm(train_dataloader)\n    for iter, (images, labels) in enumerate(progress_bar):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        # writer.add_scalar('Train/Loss', loss, epoch*len(train_dataloader)+iter)\n        progress_bar.set_description('Epoch: {}/{} Iter: {} Loss: {:.4f}'.format(epoch+1, epochs, iter+1, loss.item()))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    model.eval()\n    all_predictions = []\n    all_labels = []\n    for iter, (images, labels) in enumerate(test_dataloader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        with torch.no_grad():\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            predictions = torch.argmax(outputs.cpu(), dim=1)\n            all_predictions.extend(predictions)\n            all_labels.extend(labels.cpu())\n    all_labels = [label.item() for label in all_labels]\n    all_predictions = [prediction.item() for prediction in all_predictions]\n    acc = accuracy_score(all_labels, all_predictions)\n    print('Epoch: {}/{} Test Loss: {:.4f} Test Acc: {:.4f}'.format(epoch+1, epochs, loss.item(), acc))\n    torch.save(model.state_dict(), 'last.pt')\n    if acc > best_acc:\n        torch.save(model.state_dict(), 'best.pt')\n        best_acc=acc\n    # writer.add_scalars('Val/Accuracy', acc, epoch)","metadata":{"execution":{"iopub.status.busy":"2024-01-15T17:50:36.337226Z","iopub.execute_input":"2024-01-15T17:50:36.337508Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch: 1/20 Iter: 2401 Loss: 0.4228: 100%|██████████| 2401/2401 [06:42<00:00,  5.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1/20 Test Loss: 0.9839 Test Acc: 0.7737\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 2/20 Iter: 2401 Loss: 0.4437: 100%|██████████| 2401/2401 [06:34<00:00,  6.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 2/20 Test Loss: 0.8342 Test Acc: 0.7260\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 3/20 Iter: 2401 Loss: 1.2457: 100%|██████████| 2401/2401 [06:33<00:00,  6.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 3/20 Test Loss: 1.3230 Test Acc: 0.7858\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 4/20 Iter: 2401 Loss: 0.2581: 100%|██████████| 2401/2401 [06:32<00:00,  6.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 4/20 Test Loss: 1.4520 Test Acc: 0.7734\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 5/20 Iter: 2401 Loss: 0.7783: 100%|██████████| 2401/2401 [06:34<00:00,  6.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 5/20 Test Loss: 0.6421 Test Acc: 0.7538\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 6/20 Iter: 2401 Loss: 0.8843: 100%|██████████| 2401/2401 [06:33<00:00,  6.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 6/20 Test Loss: 0.8139 Test Acc: 0.7861\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 7/20 Iter: 2401 Loss: 0.3128: 100%|██████████| 2401/2401 [06:34<00:00,  6.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 7/20 Test Loss: 0.9617 Test Acc: 0.7858\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 8/20 Iter: 2401 Loss: 0.3019: 100%|██████████| 2401/2401 [06:36<00:00,  6.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 8/20 Test Loss: 0.9713 Test Acc: 0.7901\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 9/20 Iter: 2401 Loss: 1.0295: 100%|██████████| 2401/2401 [06:37<00:00,  6.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 9/20 Test Loss: 0.6795 Test Acc: 0.7874\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 10/20 Iter: 2401 Loss: 0.0088: 100%|██████████| 2401/2401 [06:37<00:00,  6.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10/20 Test Loss: 0.9304 Test Acc: 0.7848\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 11/20 Iter: 2401 Loss: 0.1339: 100%|██████████| 2401/2401 [06:37<00:00,  6.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 11/20 Test Loss: 0.6627 Test Acc: 0.7829\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 12/20 Iter: 2401 Loss: 0.3980: 100%|██████████| 2401/2401 [06:38<00:00,  6.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 12/20 Test Loss: 0.8689 Test Acc: 0.7727\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 13/20 Iter: 1088 Loss: 0.1095:  45%|████▌     | 1087/2401 [03:00<03:36,  6.08it/s]","output_type":"stream"}]},{"cell_type":"code","source":"test_model = MyEffnet().to(device)\ntest_model.load_state_dict(torch.load('best.pt', map_location=torch.device('cpu')))\ntest_model.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport random\n%matplotlib inline\ncategories = [\"dark\", \"light\", \"mid-dark\", \"mid-light\"]\nindices = random.sample(range(0, test_dataset.__len__()), 8)\nprint(indices)\nimages = torch.stack([test_dataset.__getitem__(i)[0] for i in indices])\n# images = torch.from_numpy(images)\n# print(images)\n# # labels = [categories[int(test_dataset.__getitem__(i)[1])] for i in indices]\nlabels = [test_dataset.__getitem__(i)[1] for i in indices]\npredictions = torch.argmax(test_model(images.to(device)).cpu(), dim=1)\nprint(images.shape)\nprint(labels)\nprint(predictions","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 4, figsize=(10, 5))\naxes = axes.flatten()\nfor i in range(8):\n  img = cv2.imread(test_dataset.image_paths[indices[i]])\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n  axes[i].imshow(img)\n  title = f\"Prediction: {categories[predictions[i]]}\"\n\n  # if labels is not None:\n  #     title += f\"\\nTrue Label: {categories[labels[i]]}\"\n\n  axes[i].set_title(title)\n  axes[i].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}